agent:
  name: "go2"
  urdf: "./Pretrain/urdfs/go2_description/urdf/go2_description.urdf"
  n_dofs: 12
  object_dim: 3
  joint_name:
    - "FR_hip_joint"
    - "FR_thigh_joint"
    - "FR_calf_joint"
    - "FL_hip_joint"
    - "FL_thigh_joint"
    - "FL_calf_joint"
    - "RR_hip_joint"
    - "RR_thigh_joint"
    - "RR_calf_joint"
    - "RL_hip_joint"
    - "RL_thigh_joint"
    - "RL_calf_joint"
  init_angles:
    - 0.0   # FR_hip_joint
    - 0.8   # FR_thigh_joint
    - -1.5  # FR_calf_joint
    - 0.0   # FL_hip_joint
    - 0.8   # FL_thigh_joint
    - -1.5  # FL_calf_joint
    - 0.0   # RR_hip_joint
    - 1.0   # RR_thigh_joint
    - -1.5  # RR_calf_joint
    - 0.0   # RL_hip_joint
    - 1.0   # RL_thigh_joint
    - -1.5  # RL_calf_joint
  end_effector: [11, 20, 29, 38]


rl:
  env:
    kp: 20.0
    kd: 0.5
    termination_if_roll_greater_than: 10
    termination_if_pitch_greater_than: 10
    base_init_pos: [0.0, 0.0, 0.42]
    base_init_quat: [1.0, 0.0, 0.0, 0.0]
    episode_length_s: 20.0
    resampling_time_s: 4.0
    action_scale: 0.25
    simulate_action_latency: true
    clip_actions: 100.0
    dt: 0.02

  obs:
    num_obs: 72
    obs_scales:
      lin_vel: 2.0
      ang_vel: 0.25
      dof_pos: 1.0
      dof_vel: 0.05

  reward:
    tracking_sigma: 0.25
    base_height_target: 0.3
    feet_height_target: 0.075
    reward_scales:
      tracking_hop: 20.0

      action_rate: -0.005
      similar_to_default: -0.1


  command:
    num_commands: 16
    # locomote
    lin_vel_x_range: [-0.0, 0.0]
    lin_vel_y_range: [-0.0, 0.0]
    ang_vel_range:   [-0.0, 0.0]

    # body pose
    dz_range: [ -0.0, 0.0 ]
    pitch_range: [ -0.0, 0.0 ]  # rad
    roll_range: [ -0.0, 0.0 ]  # rad

    # limbvel
    ee_vx_range: [ -0.0, 0.0 ]
    ee_vy_range: [ -0.0, 0.0 ]
    ee_vz_range: [ -0.0, 0.0 ]
    imp_s_range: [ 0.0, 0.0 ]

    # contact hold
    Fn_range: [ 0.0, 0.0 ]
    vt_range: [ -0.0, 0.0 ]
    phi_range: [ -0.0, 0.0 ]

    # hop
    apex_h_range: [ 0.05, 0.4 ]
    psi_range: [ -3.1416, 3.1416 ]
    pitch_imp_range: [ -1.0, 1.0 ]

  train:
    algorithm:
      class_name: PPO
      clip_param: 0.2
      desired_kl: 0.01
      entropy_coef: 0.01
      gamma: 0.99
      lam: 0.95
      learning_rate: 0.001
      max_grad_norm: 1.0
      num_learning_epochs: 5
      num_mini_batches: 4
      schedule: adaptive
      use_clipped_value_loss: true
      value_loss_coef: 1.0
    init_member_classes: {}
    policy:
      activation: elu
      actor_hidden_dims: [512, 256, 128]
      critic_hidden_dims: [512, 256, 128]
      init_noise_std: 1.0
      class_name: ActorCritic
    runner:
      checkpoint: -1
      experiment_name: go2-walking
      load_run: -1
      log_interval: 1
      max_iterations: 201
      record_interval: -1
      resume: false
      resume_path: null
      run_name: ""
    runner_class_name: OnPolicyRunner
    num_steps_per_env: 24
    save_interval: 100
    empirical_normalization: null
    seed: 1




dataset:
  num_envs: 2048
  #num_envs: 32768
  episodes: 10000
  max_episode_seconds: 3
  frame_rate: 25

  log_dir: "Pretrain/primitives/go2-walking"
  curiosity_beta: 0.1
  policy_hidden_dim: 256
  similarity_threshold: 0.6
  downsample_factor: 5
  write_buffer_size: 5000
  loss_beta: 0.2


  agent_pos: [ 0.0, 0.0, 0.42]
  obj_pos_low: [ -0.5, -0.5, 0.0 ]
  obj_pos_high: [ 0.5, 0.5, 1.0 ]
  obj_vel_low: [ -1.5, -1.5, -1.5 ]
  obj_vel_high: [ 1.5, 1.5, 1.5 ]

model:
  vae:
    prior: "Gaussian"
    node_features: 3
    hidden_features: 128
    num_layers: 2
    rnn_hidden: 128
    latent_dim: 64
    seq_len: ${mul:${dataset.max_episode_seconds},${dataset.frame_rate}}
    hidden_dim: 128
  res_rl: {}


trainer:
  load_path: "./Pretrain/data/${agent.name}/${dataset.num_envs} ${dataset.episodes} ${dataset.max_episode_seconds} ${dataset.frame_rate}/${dataset.num_envs} ${dataset.episodes} ${dataset.max_episode_seconds} ${dataset.frame_rate}.h5"
  processed_path: './Pretrain/data/${agent.name}/${dataset.num_envs} ${dataset.episodes} ${dataset.max_episode_seconds} ${dataset.frame_rate}/preprocess.h5'
  normalizer_path: './Pretrain/data/${agent.name}/${dataset.num_envs} ${dataset.episodes} ${dataset.max_episode_seconds} ${dataset.frame_rate}/normalizers.pt'
  batch_size: 256
  device: 'cuda'
  num_epochs: 4
  optimizer:
    lr: 0.001
  beta_anneal:
    strategy: "warmup"
    warm_up: 16000
    max_beta: 0.0
    #max_beta: 0.00001
  save_path: "./Pretrain/output/${agent.name} ${model.vae.prior}/"
  kino:
    lambda_kinematic: 1.0
    lambda_dynamic: 0.0
  sim:
    lambda_sim: 1.0
    w_q: 1.0
    w_dq: 0.02
    w_p: 1.0
    w_dp : 0.02
    w_w : 0.5
    w_dw : 0.01
    w_u: 0.2
    w_du: 0.005
    w_obs: 0.0

imitator:
  processed_path: './Pretrain/data/${agent.name}/demo/preprocess.h5'
  batch_size: 256

codebook:
  delta_init: 5
  update_rule: "sphere"